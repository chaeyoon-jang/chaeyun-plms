common:
  seed: 42
  num_workers: 4
  gpu_devices: 1
  gpu: 0
  dist_url: tcp://127.0.0.1:32465
  dist_backend: nccl
  rank: 0
  world_size: 1
  distributed: true
  save_dir: ./rte
  n_epochs: 30
  
dataset:
  _name: rte
  num_classes: 2
  batch_size: 16
  max_seq_length: 300

optimizer:
  _name: adamw
  weight_decay: 0.1
  learning_rate: 2e-05
  adam_betas: [0.9, 0.98]
  adam_eps: 1e-06

lr_scheduler:
  _name: linear_decay
  warmup_ratie: 0.1

model:
  _name: roberta-base
  dropout: 0.1
  attention_dropout: 0.1